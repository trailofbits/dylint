# missing_doc_comment_llm

⚠️ DO NOT RUN THIS LINT ON PRIVATE SOURCE CODE ⚠️

### What it does

Checks for functions missing [doc comments].

### Why is this bad?

Understanding what a function does is easier given a description of the function rather than
just its code.

### Known problems

The lint is currently enabled only for functions.

### Example

```rust
pub fn foo() {}
```

Use instead:

```rust
/// A doc comment generated by an LLM.
pub fn foo() {}
```

### LLM Integration

The lint will suggest a doc comment generated by an LLM via the [litellm-rs] library.
The appropriate API key environment variable must be set based on the model being used
(e.g., `ANTHROPIC_API_KEY` for Anthropic models, `OPENAI_API_KEY` for OpenAI models).
The prompt sent to the LLM has the following form:

````ignore
```rust
<function declaration>
```
An elaborate, high quality rustdoc comment for the above function:
```rust
````

The prompt's [`stop` parameter] is set to `["\n```"]`. Thus, the LLM should stop generating
tokens once the second code block is complete. The suggested doc comment is the one that
appears in that code block, if any.

The phrase "An elaborate..." is configurable (see below).

### Configuration

Certain [LLM parameters] can be configured by setting them in the
`missing_doc_comment_llm` table of the linted workspace's [`dylint.toml` file]. Example:

```toml
[missing_doc_comment_llm]
prompt = "A rustdoc comment for the above function with a \"Motivation\" section:"
temperature = 1.0
```

The following parameters are supported:

- `prompt` (default "An elaborate, high quality rustdoc comment for the above function:").
  This default is based on the [Write a Python docstring] example.
- `model` (default "gpt-3.5-turbo")
- `temperature` (default 0.2). Note that this default is less than the typical default (1.0).
  Per the [`temperature` documentation], "Higher values like 0.8 will make the output more
  random, while lower values like 0.2 will make it more focused and deterministic."
- `top_p` (default none, i.e., use provider's default)
- `presence_penalty` (default none, i.e., use provider's default)
- `frequency_penalty` (default none, i.e., use provider's default)

[LLM parameters]: https://platform.openai.com/docs/api-reference/chat/create
[Write a Python docstring]: https://platform.openai.com/examples/default-python-docstring
[`dylint.toml` file]: https://github.com/trailofbits/dylint#configurable-libraries
[`stop` parameter]: https://platform.openai.com/docs/api-reference/chat/create#chat-create-stop
[`temperature` documentation]: https://platform.openai.com/docs/api-reference/chat/create#chat-create-temperature
[doc comments]: https://doc.rust-lang.org/rust-by-example/meta/doc.html#doc-comments
[litellm-rs]: https://docs.rs/litellm-rs/
